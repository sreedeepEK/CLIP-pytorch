### CLIP (Contrastive Language-Image Pretraining) model in PyTorch

Implementation of the CLIP (Contrastive Language-Image Pretraining) model in PyTorch for learning visual representations from natural language supervision.

NOTE: This project is under development. Read more about the paper [here](https://openai.com/index/clip/)